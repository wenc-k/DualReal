# DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization

üéâüéâ Our paper, ‚ÄúDualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video
Customization‚Äù accepted by ICCV 2025!
**Our [demo page](https://wenc-k.github.io/dualreal/).**

## Showcase


## TODO List

- [x] Release the paper and demo page. Visit [https://wenc-k.github.io/dualreal/](https://wenc-k.github.io/dualreal/) 
- [x] Release the code.


## Requirements
The training and inference are conducted on 1 A100 GPU (80GB VRAM)
## Setup
```
git clone https://github.com/wenc-k/DualReal.git
cd DualReal
```


## Environment
All the tests are conducted in Linux. We suggest running our code in Linux. To set up our environment in Linux, please run:
```
conda create -n dualreal python=3.10 -y
conda activate dualreal

pip install -r requirements.txt
```

```
cd train

git clone https://github.com/huggingface/diffusers.git
cd diffusers 
pip install -e .
```


## Checkpoints
1. please download the pre-trained CogVideoX-5b checkpoints from [here](https://huggingface.co/THUDM/CogVideoX-5b), and put the whole folder under `DualReal`, it should look like `DualReal/CogVideoX-5b`

2. please download the open_clip_pytorch_model.bin from [here](https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K/tree/main), and put the file under `DualReal/train/pretrained`, it should look like `DualReal/train/pretrained/open_clip_pytorch_model.bin`



## Customize your Identity and Motion!



## Citation:
Don't forget to cite this source if it proves useful in your research!
```
@article{wang2025dualreal,
  title={DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization},
  author={Wang, Wenchuan and Huang, Mengqi and Tu, Yijing and Mao, Zhendong},
  journal={arXiv preprint arXiv:2505.02192},
  year={2025}
}
```